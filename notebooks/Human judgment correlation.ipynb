{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "mpl.style.use('ggplot')\n",
    "from matplotlib.backends.backend_pgf import FigureCanvasPgf\n",
    "mpl.backend_bases.register_backend('pgf', FigureCanvasPgf)\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys, os\n",
    "from os.path import join\n",
    "sys.path.append(\"../tools/\")\n",
    "from collections import defaultdict\n",
    "\n",
    "# Data management libraries\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "# Treebank utils, found in \"../tools\"\n",
    "import udeval, udtree, lang_utils, dependency_classes\n",
    "\n",
    "file_format = \"conllu\"\n",
    "train_type = \"train\"\n",
    "fine_grained_deprels = False\n",
    "gold_output_base = \"/Users/jimmy/dev/edu/nlp-rod/udeval/resources/universaldependencies1-2/universal-dependencies-1.2/\"\n",
    "\n",
    "\n",
    "\n",
    "def attachment_score_per_tree(system_output_path, gold_path, labeled=True, fine_grained_deprels=False, include_punct=False):\n",
    "    if not include_punct:\n",
    "        puncts = set.union(udeval.is_only_punctuation(gold_path), {'punct'})\n",
    "    system = udtree.from_files(system_output_path)\n",
    "    gold = udtree.from_files(gold_path)\n",
    "    correct, incorrect = 0, 0\n",
    "    res = []\n",
    "    for system_tree, gold_tree in zip(system, gold):\n",
    "        correct, incorrect = 0, 0\n",
    "        (tree_correct,\n",
    "         tree_incorrect) = udeval.match_tree_attachments(system_tree, gold_tree, labeled,\n",
    "                                                         fine_grained_deprels=fine_grained_deprels,\n",
    "                                                         ignore_deprels=puncts)\n",
    "        correct += len(tree_correct)\n",
    "        incorrect += len(tree_incorrect)\n",
    "\n",
    "        if (correct + incorrect) == 0:\n",
    "            res.append(float(\"NaN\"))\n",
    "        \n",
    "        res.append(correct / (correct + incorrect))\n",
    "    return res\n",
    "    \n",
    "\n",
    "def weighted_las(system_output_path, gold_path, weights, include_punct=False):\n",
    "    if not include_punct:\n",
    "        puncts = set.union(udeval.is_only_punctuation(gold_path), {'punct'})\n",
    "    system = udtree.from_files(system_output_path)\n",
    "    gold = udtree.from_files(gold_path)\n",
    "    res = []\n",
    "    for system_tree, gold_tree in zip(system, gold):\n",
    "        correct, incorrect = 0, 0\n",
    "        (tree_correct,\n",
    "           tree_incorrect) = udeval.match_tree_attachments(system_tree, gold_tree, True,\n",
    "                                                  fine_grained_deprels=False,\n",
    "                                                          ignore_deprels=puncts)\n",
    "        for _, _, _, gold_label in tree_correct:\n",
    "            correct += weights[gold_label]\n",
    "\n",
    "        for _, _, _, gold_label in tree_incorrect:\n",
    "            incorrect += weights[gold_label]\n",
    "\n",
    "        if (correct + incorrect) == 0:\n",
    "            res.append(float(\"NaN\"))\n",
    "        res.append(correct / (correct + incorrect))\n",
    "    return res\n",
    "\n",
    "\n",
    "    \n",
    "def labels_precision_per_tree(system_output_path,\n",
    "                            gold_path,\n",
    "                            labels=[\"nsubj\", \"nsubjpass\"],\n",
    "                            fine_grained_deprels=True):\n",
    "    system = udtree.from_files(system_output_path)\n",
    "    gold = udtree.from_files(gold_path)\n",
    "    results = []\n",
    "    for system_tree, gold_tree in zip(system, gold):\n",
    "        system_correct, system_incorrect, gold_count = 0, 0, 0\n",
    "        (tree_correct,\n",
    "         tree_incorrect) = udeval.match_tree_attachments(system_tree, gold_tree, True,\n",
    "                                                  fine_grained_deprels=fine_grained_deprels)\n",
    "        for _, system_label, _, _ in tree_correct:\n",
    "            if system_label in labels:\n",
    "                system_correct += 1\n",
    "                gold_count += 1\n",
    "        for _, system_label, _, gold_label in tree_incorrect:\n",
    "            if gold_label in labels:\n",
    "                gold_count += 1\n",
    "            if system_label in labels:\n",
    "                system_incorrect += 1\n",
    "\n",
    "        if system_correct + system_incorrect == 0:\n",
    "            precision = float(\"NaN\")\n",
    "        else:\n",
    "            precision = system_correct / (system_correct + system_incorrect)\n",
    "        results.append((precision))\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "def labels_recall_per_tree(system_output_path,\n",
    "                            gold_path,\n",
    "                            labels=[\"nsubj\", \"nsubjpass\"],\n",
    "                            fine_grained_deprels=True):\n",
    "    system = udtree.from_files(system_output_path)\n",
    "    gold = udtree.from_files(gold_path)\n",
    "    results = []\n",
    "    for system_tree, gold_tree in zip(system, gold):\n",
    "        system_correct, system_incorrect, gold_count = 0, 0, 0\n",
    "        (tree_correct,\n",
    "         tree_incorrect) = udeval.match_tree_attachments(system_tree, gold_tree, True,\n",
    "                                                  fine_grained_deprels=fine_grained_deprels)\n",
    "        for _, system_label, _, _ in tree_correct:\n",
    "            if system_label in labels:\n",
    "                system_correct += 1\n",
    "                gold_count += 1\n",
    "        for _, system_label, _, gold_label in tree_incorrect:\n",
    "            if gold_label in labels:\n",
    "                gold_count += 1\n",
    "            if system_label in labels:\n",
    "                system_incorrect += 1\n",
    "\n",
    "        if gold_count == 0:\n",
    "            recall = float(\"NaN\")\n",
    "        else:\n",
    "            recall = system_correct / gold_count\n",
    "        results.append(recall)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content precision</th>\n",
       "      <th>Content recall</th>\n",
       "      <th>LAS</th>\n",
       "      <th>WLAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English</th>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.581423</td>\n",
       "      <td>0.545157</td>\n",
       "      <td>0.546863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German</th>\n",
       "      <td>0.371537</td>\n",
       "      <td>0.437564</td>\n",
       "      <td>0.463736</td>\n",
       "      <td>0.463736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>0.448713</td>\n",
       "      <td>0.463425</td>\n",
       "      <td>0.490216</td>\n",
       "      <td>0.478960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Content precision  Content recall       LAS      WLAS\n",
       "English           0.508442        0.581423  0.545157  0.546863\n",
       "German            0.371537        0.437564  0.463736  0.463736\n",
       "Spanish           0.448713        0.463425  0.490216  0.478960"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_weights = pd.Series.from_csv('../data/function_content_degree.wde.csv')\n",
    "#ind_weights = pd.DataFrame.from_csv('../data/function_content_degree.individual_languages.wde.csv')\n",
    "langs = [('en', 'English'), ('es', 'Spanish'), ('de', 'German')]\n",
    "annotators = {}\n",
    "for langcode, lang in langs:\n",
    "    annotators[lang] = pd.Series.from_csv('../resources/plank_conll2015/datapackage/{}/prediction'.format(langcode), header=None, index_col=None).map({'blue': 0, 'red': 1})\n",
    "\n",
    "las = lambda system, gold: attachment_score_per_tree(system, gold)\n",
    "avg_wlas = lambda system, gold: weighted_las(system, gold, weights=avg_weights)\n",
    "#ind_wlas = lambda system, gold, lang: weighted_las(system, gold, weights=ind_weights[lang])\n",
    "content_precision = lambda system, gold: labels_precision_per_tree(system, gold, labels=dependency_classes.content_dependents)\n",
    "content_recall = lambda system, gold: labels_recall_per_tree(system, gold, labels=dependency_classes.content_dependents)\n",
    "metrics = [('LAS', las), ('WLAS', avg_wlas), ('Content precision', content_precision), ('Content recall', content_recall)]\n",
    "\n",
    "corrs = defaultdict(dict)\n",
    "for langcode, lang in langs:\n",
    "    for mname, metric in metrics:\n",
    "#        if metric == ind_wlas:\n",
    "#            metric = lambda system, gold: ind_wlas(system, gold, lang)\n",
    "        gold = '../resources/plank_conll2015/datapackage/{}/gold.conll'.format(langcode)\n",
    "        parser1 = metric('../resources/plank_conll2015/datapackage/{}/parser1.conll'.format(langcode), gold)\n",
    "        parser2 = metric('../resources/plank_conll2015/datapackage/{}/parser2.conll'.format(langcode), gold)\n",
    "        diffs = pd.DataFrame({\"Parser 1\": parser1, \"Parser 2\": parser2})\n",
    "        diffs = (diffs['Parser 2'].subtract(diffs['Parser 1'])).map(lambda x: 0 if x < 0 else 1)\n",
    "        diffs = pd.concat([diffs, annotators[lang]], axis=1)\n",
    "        corrs[mname][lang] = diffs.corr('pearson').ix[0,1]\n",
    "\n",
    "\n",
    "\n",
    "corrs = pd.DataFrame(corrs)\n",
    "corrs.to_csv('../data/human_judgment_corr.csv')\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg           0.056917\n",
       "cc            0.132400\n",
       "punct         0.183170\n",
       "mark          0.222706\n",
       "mwe           0.250968\n",
       "auxpass       0.264134\n",
       "cop           0.274486\n",
       "aux           0.276254\n",
       "case          0.283542\n",
       "expl          0.283816\n",
       "det           0.308794\n",
       "csubjpass     0.341963\n",
       "discourse     0.346308\n",
       "vocative      0.376562\n",
       "dep           0.379487\n",
       "foreign       0.420653\n",
       "goeswith      0.423262\n",
       "dislocated    0.437807\n",
       "nummod        0.469234\n",
       "reparandum    0.471234\n",
       "iobj          0.474883\n",
       "parataxis     0.476370\n",
       "compound      0.477336\n",
       "list          0.479554\n",
       "remnant       0.502777\n",
       "csubj         0.507759\n",
       "nsubjpass     0.526781\n",
       "advmod        0.538054\n",
       "name          0.565665\n",
       "xcomp         0.592473\n",
       "appos         0.599161\n",
       "ccomp         0.613860\n",
       "advcl         0.649315\n",
       "acl           0.672400\n",
       "nsubj         0.681228\n",
       "root          0.701767\n",
       "dobj          0.711663\n",
       "amod          0.712432\n",
       "nmod          0.784227\n",
       "conj          0.787191\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
